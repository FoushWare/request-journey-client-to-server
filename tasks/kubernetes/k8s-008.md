# Task: Kubernetes Monitoring & Observability
**Issue:** #129 | **Category:** Kubernetes | **Priority:** High | **Effort:** 8h

---

## üìã Objective

Implement comprehensive monitoring, logging, and observability for Kubernetes cluster and applications.

---

## üìù Description

Set up observability stack for Kubernetes including:
- Prometheus for metrics collection
- Grafana for visualization
- ELK Stack for logging
- Jaeger for distributed tracing
- Alerting rules and dashboards

---

## ‚úÖ Acceptance Criteria

- [ ] Prometheus deployed and scraping metrics
- [ ] Grafana dashboards created
- [ ] ELK Stack logging configured
- [ ] Jaeger tracing enabled
- [ ] Alerting rules configured
- [ ] Alert notifications working
- [ ] Log aggregation functional
- [ ] Performance baselines established
- [ ] Team trained on observability
- [ ] Runbooks created for common issues

---

## üîß Sub-Tasks

### 1. Prometheus Installation & Configuration
- [ ] Deploy Prometheus to cluster
- [ ] Configure ServiceMonitor for pods
- [ ] Set up scrape configurations
- [ ] Configure retention policies
- [ ] Set up storage for metrics
- [ ] Test metric collection

### 2. Prometheus Metrics Collection
- [ ] Configure node exporter
- [ ] Configure kube-state-metrics
- [ ] Configure kubelet metrics
- [ ] Configure application metrics
- [ ] Verify metric collection
- [ ] Document metric schema

### 3. Grafana Installation & Dashboards
- [ ] Install Grafana
- [ ] Configure Prometheus data source
- [ ] Create cluster overview dashboard
- [ ] Create per-service dashboards
- [ ] Create infrastructure dashboard
- [ ] Create application health dashboard

### 4. Key Metrics Monitoring
- [ ] Monitor pod CPU/memory usage
- [ ] Monitor node resource allocation
- [ ] Monitor network I/O
- [ ] Monitor disk usage
- [ ] Monitor container startup time
- [ ] Monitor application response times

### 5. Alerting Rules Configuration
- [ ] Create high CPU alerts
- [ ] Create high memory alerts
- [ ] Create disk space alerts
- [ ] Create pod restart alerts
- [ ] Create availability alerts
- [ ] Create error rate alerts

### 6. Alert Notification Channels
- [ ] Configure Slack integration
- [ ] Configure email alerts
- [ ] Configure PagerDuty integration
- [ ] Configure webhook notifications
- [ ] Test alert routing
- [ ] Document alert escalation

### 7. Elasticsearch & Kibana Setup
- [ ] Deploy Elasticsearch cluster
- [ ] Deploy Kibana for visualization
- [ ] Configure index lifecycle
- [ ] Set up log parsing
- [ ] Create Kibana dashboards
- [ ] Test log search and filtering

### 8. Log Collection Configuration
- [ ] Deploy Fluentd/Logstash
- [ ] Configure container log collection
- [ ] Configure application log parsing
- [ ] Set up log enrichment
- [ ] Configure field extraction
- [ ] Test log delivery

### 9. Jaeger Tracing Setup
- [ ] Deploy Jaeger All-in-One
- [ ] Configure applications for tracing
- [ ] Configure trace sampling
- [ ] Set up trace storage
- [ ] Create tracing dashboards
- [ ] Test distributed tracing

### 10. Observability Best Practices
- [ ] Document metric naming conventions
- [ ] Document dashboard standards
- [ ] Create runbooks for common issues
- [ ] Implement SLO/SLI tracking
- [ ] Create team training materials
- [ ] Schedule knowledge sharing sessions

---

## üìö Learning Resources

- **Prometheus:** https://prometheus.io/
- **Grafana:** https://grafana.com/
- **Elasticsearch:** https://www.elastic.co/
- **Jaeger:** https://www.jaegertracing.io/
- **Kubernetes Monitoring:** https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/

---

## üíª Code Example: Prometheus Configuration

```yaml
---
# Prometheus ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: production
        environment: prod
    
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093
    
    rule_files:
    - /etc/prometheus/rules/*.yml
    
    scrape_configs:
    # Prometheus self-monitoring
    - job_name: prometheus
      static_configs:
      - targets: ['localhost:9090']
    
    # Kubernetes API server
    - job_name: kubernetes-apiservers
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
    
    # Kubernetes nodes
    - job_name: kubernetes-nodes
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
    
    # Pod metrics via ServiceMonitor
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: "true"
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

---
# Prometheus Rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  alerts.yml: |
    groups:
    - name: kubernetes
      interval: 30s
      rules:
      # Node alerts
      - alert: HighNodeCPU
        expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 75
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on node {{ $labels.node }}"
          description: "CPU usage is above 75% for 5 minutes"
      
      - alert: HighNodeMemory
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on node {{ $labels.node }}"
      
      # Pod alerts
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[1h]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Pod {{ $labels.pod }} is crash looping"
      
      - alert: PodNotHealthy
        expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"})[15m:1m]) > 0
        labels:
          severity: critical
        annotations:
          summary: "Pod {{ $labels.pod }} is not healthy"
      
      # Application alerts
      - alert: HighErrorRate
        expr: (rate(http_requests_total{status=~"5.."}[5m]) > 0.01)
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate on {{ $labels.service }}"
      
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time on {{ $labels.service }}"

---
# Prometheus Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.40.0
        args:
        - "--config.file=/etc/prometheus/prometheus.yml"
        - "--storage.tsdb.path=/prometheus"
        - "--storage.tsdb.retention.time=15d"
        - "--web.console.libraries=/usr/share/prometheus/console_libraries"
        - "--web.console.templates=/usr/share/prometheus/consoles"
        ports:
        - containerPort: 9090
          name: http
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: rules
          mountPath: /etc/prometheus/rules
        - name: storage
          mountPath: /prometheus
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 1000m
            memory: 4Gi
      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: rules
        configMap:
          name: prometheus-rules
      - name: storage
        emptyDir: {}
```

---

## üìä Grafana Dashboard Example

```json
{
  "dashboard": {
    "title": "Kubernetes Cluster Overview",
    "panels": [
      {
        "title": "CPU Usage",
        "targets": [
          {
            "expr": "sum(rate(container_cpu_usage_seconds_total[5m]))"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "targets": [
          {
            "expr": "sum(container_memory_working_set_bytes) / sum(kube_pod_container_resource_limits_memory_bytes)"
          }
        ]
      },
      {
        "title": "Pod Restarts",
        "targets": [
          {
            "expr": "sum(rate(kube_pod_container_status_restarts_total[1h]))"
          }
        ]
      }
    ]
  }
}
```

---

## üîê Security Considerations

- **RBAC:** Limit access to monitoring data
- **Data Retention:** Implement data privacy policies
- **Credentials:** Secure API keys and tokens
- **Network Policies:** Restrict access to monitoring systems
- **Audit Logging:** Log access to sensitive metrics
- **Encryption:** Encrypt metrics in transit and at rest

---

## ‚ú® Success Metrics

- 100% uptime of monitoring system
- Metric latency < 30 seconds
- Alert notification < 1 minute
- Dashboard load time < 3 seconds
- Team response time to alerts < 5 minutes
- SLO achievement > 99.9%

---

## üìñ Related Tasks

- [K8s Deployment](k8s-002.md) - Application deployment
- [Logging Configuration](logging-001.md) - Log aggregation
- [Alert Management](frontend-010.md) - Alert UI

---

**Created:** January 17, 2026 | **Last Updated:** January 17, 2026
